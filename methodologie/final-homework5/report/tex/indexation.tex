\subsection{Indexation}

\subsubsection{Bib\TeX{} analysis and reference}

\textit{Indexing, indexing, indexing\ldots}

librairies
\cite{Lawrence99digitallibraries}

Improving search
\cite{Reynolds_efficientpeer-to-peer}

\cite{Yang02improvingsearch}


\subsubsection{No double utility}

Manage a large amount of articles is very complicated. The titles
are not always very precise, and some file could be actually the same.
A main interest of our system is the impossibility for a 
file to be doubled. Every file is identified by its hash and its
meta-information. Therefore there is no possibility of double. In
case of a mistake from the administrators, the distance (defined in
this article) between
an article in its slightly altered copy will be very low. This could
be a sign that something went wrong and the copy could be erased in
order to keep the system clean.
