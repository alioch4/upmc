\subsection{Application}

\subsubsection{Different ranking methods}

One of the main problem for a paper to be read is the reference. It's
quite hard for a new paper to be as well-referenced than an old one.

But new scientists need to read all the classical and seminal 
articles before start to read the most recent one.

In order to satisfy this two requirements, two ranking system will
be installed. One will be based on the amount of reference that an
article can get. And the other one with a mix of publication date,
reference in other article, and h-index of scientists.

The main goal here is to provide a quick and efficient way for
experienced scientists to read easily the new article of their fields
and for new one to get quickly the "must read" of their field.

\subsubsection{Simplified accounts for users}

The main interest to be using a P2P system where hashes could be use massively is
to be able to describe an account with only a list of hashes.
In fact all the information are inside the network. It's very easy to fetch an information
to read it but it's not always useful to keep it in memory.

In order to counter the problem of space to log history of the users, only hashes
related to users will be stored on the user administration interface.

For instance, a scientist is having interest in particle physics and got 65
articles in his account. In order to discribe this account, only the 65 hashes are needed.
It's really easy to handle a amount of data so small and the system can scale up really easily
because hashes are quite smaller than the articles themselves.

\subsubsection{RSS utilities}

Stay informed of the current situation of research is a daily
activity for scientists. Conference give regulary good articles but
not all fields are exposed in the released papers. A paper coming from
a small university can be completly ignored if it's not referenced by
other people.

In order to stay in touch with the new article a RSS 
(Really simple syndication) will be provided. It will allow scientists
to follow a specific field of research by using hashtags and a system
of keywords.

\subsubsection{Graphical user interface to manage the current personnal repository}

System administrors like to manipulate application with script to be update, installed
systematically. In order to do that, we must provide a command line interface in order
to update and configure easily the application by scripting.

Most of scientists are not computer science scientist and don't have a very deep (or interest)
for computing. In order to provide them a good user experience we must also provide a good 
graphical interface. Because users are a critical ressource for our P2P network we 
must lure in a lot of user to have an efficient P2P system. Good example
of tools can be found on the MacOSX platform but all of them
are not standard. Also the web seems to be a very good alternative
to all "platform" solution. By using a web-browser in order
to provide graphical interface to system. All the platform-dependant
difficulties are skipped to provide quickly a good interface whatever
the platform is.

\subsubsection{Meta information about files}

The main interest of our network is to provide an efficient way to parse and
index all the content of a file in order to only share meta-information about the
file but not the file itself. In fact PDF file must be heavy (especially if
they content figures, illustrations,\ldots) in order to avoid useless network usage,
only meta-information will be shared with other peers at the beginning. When a file
will be requested by other peers, the real PDF file will then be sent on the network.

If the repository are mirroring all the time other repository both (meta information and
PDF file) will be sent to the requesting peer.

\subsubsection{Files distance}

New article are sometimes not relevant enough in order to find some works that are
close enough to a specific field. In order to solve the problem of the suggestions of
reading (that is already partially solved with the two ranking system) we can also
introduce a "distance" concept between articles.

Articles have a lot of keywords inside them. Science article are very precise and 
the words used to write them are also precise. We can use this precision in order to build a 
keyword system with the following method. Each article could be parse in order to produce 
a dictionnary of keywords (keywords and number of repetition of this keyword). Two 
dictionnaries can be compared to each other, the results of this comparaison could tell
how alike two articles are. The closer an unknown article is of an interesting article for a scientist
the more likely it's going to be useful for them to read it.
